{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "607ef78c-bad3-4306-9a66-401f2a0b2cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.9/site-packages/torch/cuda/__init__.py:611: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid, Flickr\n",
    "from torch_geometric.loader import GraphSAINTRandomWalkSampler, GraphSAINTNodeSampler\n",
    "\n",
    "from transformers import GPT2Model\n",
    "\n",
    "# load the modeules I wrote\n",
    "from graph_gpt_classification import Graph_GPT_Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4996c4d-9977-4175-afbe-24fde1f2c648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[89250, 500], edge_index=[2, 899756], y=[89250], train_mask=[89250], val_mask=[89250], test_mask=[89250])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset = Planetoid(root = '/tmp/Cora', name = 'Cora')\n",
    "dataset = Flickr(root = './tmp/Flickr')\n",
    "\n",
    "# check data\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f447c49f-1950-4a70-850e-c289e08edd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = GraphSAINTNodeSampler(\n",
    "    dataset[0],\n",
    "    batch_size = 1280, \n",
    "    num_steps = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cf5d2a5-a8ea-4c2a-ba23-5221b3ec67d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32ec6041-f4f5-41a6-850e-72a00361acb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph_GPT_Classification(\n",
       "  (g_conv_1): GCNConv(500, 768)\n",
       "  (transformer_layers): ModuleList(\n",
       "    (0-5): 6 x GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (act): NewGELUActivation()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (g_conv_2): GCNConv(768, 7)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initilize model\n",
    "gpt_model = GPT2Model.from_pretrained('distilgpt2')\n",
    "graph_gpt_model = Graph_GPT_Classification(gpt_model,\n",
    "                                           dataset.num_node_features, \n",
    "                                           128,\n",
    "                                           dataset.num_classes)\n",
    "\n",
    "graph_gpt_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcf0a276-2b0b-42b5-94bc-ac9e11b5ce18",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = GraphSAINTNodeSampler(\n",
    "    dataset[0],\n",
    "    batch_size = 128, \n",
    "    num_steps = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "436d46a5-5241-42a8-b1a8-78733dbea344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, step: 10, training loss: 16.852779388427734, testing loss: 15.763978958129883\n",
      "Accuracy: 0.3429\n",
      "epoch: 1, step: 20, training loss: 12.42660903930664, testing loss: 8.590229988098145\n",
      "Accuracy: 0.2308\n",
      "epoch: 1, step: 30, training loss: 9.657149314880371, testing loss: 7.8424391746521\n",
      "Accuracy: 0.3913\n",
      "epoch: 1, step: 40, training loss: 8.627907752990723, testing loss: 7.771993637084961\n",
      "Accuracy: 0.3333\n",
      "epoch: 1, step: 50, training loss: 8.068082809448242, testing loss: 5.506824016571045\n",
      "Accuracy: 0.3793\n",
      "epoch: 1, step: 60, training loss: 7.083344459533691, testing loss: 10.865238189697266\n",
      "Accuracy: 0.2609\n",
      "epoch: 1, step: 70, training loss: 5.7629218101501465, testing loss: 7.5988969802856445\n",
      "Accuracy: 0.2069\n",
      "epoch: 1, step: 80, training loss: 6.7849016189575195, testing loss: 5.192543983459473\n",
      "Accuracy: 0.2821\n",
      "epoch: 1, step: 90, training loss: 5.071207523345947, testing loss: 5.8787689208984375\n",
      "Accuracy: 0.3125\n",
      "epoch: 1, step: 100, training loss: 4.722263813018799, testing loss: 3.9749152660369873\n",
      "Accuracy: 0.3095\n",
      "epoch: 1, step: 110, training loss: 4.3097686767578125, testing loss: 6.307394981384277\n",
      "Accuracy: 0.2308\n",
      "epoch: 1, step: 120, training loss: 4.144293785095215, testing loss: 4.268890857696533\n",
      "Accuracy: 0.3704\n",
      "epoch: 1, step: 130, training loss: 4.242889404296875, testing loss: 3.964508533477783\n",
      "Accuracy: 0.3667\n",
      "epoch: 1, step: 140, training loss: 4.379233360290527, testing loss: 5.437081813812256\n",
      "Accuracy: 0.2353\n",
      "epoch: 1, step: 150, training loss: 4.007593631744385, testing loss: 3.8052399158477783\n",
      "Accuracy: 0.3871\n",
      "epoch: 1, step: 160, training loss: 3.742863178253174, testing loss: 3.5639700889587402\n",
      "Accuracy: 0.2895\n",
      "epoch: 1, step: 170, training loss: 3.855238437652588, testing loss: 3.8996188640594482\n",
      "Accuracy: 0.3636\n",
      "epoch: 1, step: 180, training loss: 3.139930248260498, testing loss: 3.590575695037842\n",
      "Accuracy: 0.3929\n",
      "epoch: 1, step: 190, training loss: 3.903916120529175, testing loss: 2.239922523498535\n",
      "Accuracy: 0.3125\n",
      "epoch: 1, step: 200, training loss: 2.074568033218384, testing loss: 3.1389431953430176\n",
      "Accuracy: 0.2188\n",
      "epoch: 1, step: 210, training loss: 3.503347158432007, testing loss: 2.612994432449341\n",
      "Accuracy: 0.3056\n",
      "epoch: 1, step: 220, training loss: 3.798807144165039, testing loss: 3.336336612701416\n",
      "Accuracy: 0.1892\n",
      "epoch: 1, step: 230, training loss: 3.473529100418091, testing loss: 3.41818904876709\n",
      "Accuracy: 0.2286\n",
      "epoch: 1, step: 240, training loss: 2.434692144393921, testing loss: 3.3496949672698975\n",
      "Accuracy: 0.3000\n",
      "epoch: 1, step: 250, training loss: 2.939533233642578, testing loss: 3.617561101913452\n",
      "Accuracy: 0.2333\n",
      "epoch: 1, step: 260, training loss: 2.605536937713623, testing loss: 3.0452277660369873\n",
      "Accuracy: 0.2000\n",
      "epoch: 1, step: 270, training loss: 2.566865921020508, testing loss: 2.376288890838623\n",
      "Accuracy: 0.3529\n",
      "epoch: 1, step: 280, training loss: 2.52103328704834, testing loss: 2.2866032123565674\n",
      "Accuracy: 0.3226\n",
      "epoch: 1, step: 290, training loss: 2.1928670406341553, testing loss: 2.4033010005950928\n",
      "Accuracy: 0.2353\n",
      "epoch: 1, step: 300, training loss: 2.22123646736145, testing loss: 2.7803070545196533\n",
      "Accuracy: 0.1667\n",
      "epoch: 1, step: 310, training loss: 2.1602766513824463, testing loss: 2.899268627166748\n",
      "Accuracy: 0.4828\n",
      "epoch: 1, step: 320, training loss: 2.493795156478882, testing loss: 2.0389339923858643\n",
      "Accuracy: 0.3714\n",
      "epoch: 1, step: 330, training loss: 2.0137529373168945, testing loss: 3.657792091369629\n",
      "Accuracy: 0.2800\n",
      "epoch: 1, step: 340, training loss: 1.848445177078247, testing loss: 2.6853199005126953\n",
      "Accuracy: 0.2414\n",
      "epoch: 1, step: 350, training loss: 2.0696966648101807, testing loss: 2.5161068439483643\n",
      "Accuracy: 0.1852\n",
      "epoch: 1, step: 360, training loss: 2.853074312210083, testing loss: 1.6476727724075317\n",
      "Accuracy: 0.3214\n",
      "epoch: 1, step: 370, training loss: 2.153560161590576, testing loss: 3.1070456504821777\n",
      "Accuracy: 0.3171\n",
      "epoch: 1, step: 380, training loss: 1.7921723127365112, testing loss: 2.177966356277466\n",
      "Accuracy: 0.4194\n",
      "epoch: 1, step: 390, training loss: 2.557103157043457, testing loss: 2.334773540496826\n",
      "Accuracy: 0.3000\n",
      "epoch: 1, step: 400, training loss: 1.928902268409729, testing loss: 2.6597161293029785\n",
      "Accuracy: 0.2917\n",
      "epoch: 1, step: 410, training loss: 1.8414077758789062, testing loss: 2.1546473503112793\n",
      "Accuracy: 0.2308\n",
      "epoch: 1, step: 420, training loss: 1.8415690660476685, testing loss: 1.837613582611084\n",
      "Accuracy: 0.3590\n",
      "epoch: 1, step: 430, training loss: 1.9510037899017334, testing loss: 2.199991226196289\n",
      "Accuracy: 0.1875\n",
      "epoch: 1, step: 440, training loss: 2.3648345470428467, testing loss: 2.241163969039917\n",
      "Accuracy: 0.2143\n",
      "epoch: 1, step: 450, training loss: 2.104943037033081, testing loss: 2.1558115482330322\n",
      "Accuracy: 0.3590\n",
      "epoch: 1, step: 460, training loss: 2.2827069759368896, testing loss: 2.190748453140259\n",
      "Accuracy: 0.2857\n",
      "epoch: 1, step: 470, training loss: 2.152651786804199, testing loss: 2.2736856937408447\n",
      "Accuracy: 0.3030\n",
      "epoch: 1, step: 480, training loss: 1.7732610702514648, testing loss: 1.7653403282165527\n",
      "Accuracy: 0.4167\n",
      "epoch: 1, step: 490, training loss: 2.011194944381714, testing loss: 2.133786201477051\n",
      "Accuracy: 0.1944\n",
      "epoch: 1, step: 500, training loss: 2.4588818550109863, testing loss: 1.606420874595642\n",
      "Accuracy: 0.4444\n",
      "epoch: 1, step: 510, training loss: 1.8767611980438232, testing loss: 1.5756523609161377\n",
      "Accuracy: 0.4865\n",
      "epoch: 1, step: 520, training loss: 2.104949712753296, testing loss: 1.9727681875228882\n",
      "Accuracy: 0.2727\n",
      "epoch: 1, step: 530, training loss: 1.7395085096359253, testing loss: 2.32334566116333\n",
      "Accuracy: 0.3871\n",
      "epoch: 1, step: 540, training loss: 1.736910104751587, testing loss: 1.8725310564041138\n",
      "Accuracy: 0.2857\n",
      "epoch: 1, step: 550, training loss: 2.1870574951171875, testing loss: 1.8762586116790771\n",
      "Accuracy: 0.2121\n",
      "epoch: 1, step: 560, training loss: 1.737898349761963, testing loss: 2.232485055923462\n",
      "Accuracy: 0.2000\n",
      "epoch: 1, step: 570, training loss: 1.8458380699157715, testing loss: 2.3746745586395264\n",
      "Accuracy: 0.3243\n",
      "epoch: 1, step: 580, training loss: 1.853360891342163, testing loss: 1.6958694458007812\n",
      "Accuracy: 0.5172\n",
      "epoch: 1, step: 590, training loss: 1.966070294380188, testing loss: 1.6650985479354858\n",
      "Accuracy: 0.4054\n",
      "epoch: 1, step: 600, training loss: 1.8510388135910034, testing loss: 1.7432923316955566\n",
      "Accuracy: 0.4884\n",
      "epoch: 1, step: 610, training loss: 2.358571767807007, testing loss: 1.8792681694030762\n",
      "Accuracy: 0.4615\n",
      "epoch: 1, step: 620, training loss: 1.939225435256958, testing loss: 1.5189909934997559\n",
      "Accuracy: 0.4242\n",
      "epoch: 1, step: 630, training loss: 1.9657952785491943, testing loss: 2.341458797454834\n",
      "Accuracy: 0.3000\n",
      "epoch: 1, step: 640, training loss: 1.761033535003662, testing loss: 1.7148590087890625\n",
      "Accuracy: 0.2857\n",
      "epoch: 1, step: 650, training loss: 1.8997169733047485, testing loss: 2.20196270942688\n",
      "Accuracy: 0.3871\n",
      "epoch: 1, step: 660, training loss: 2.0408215522766113, testing loss: 2.1563446521759033\n",
      "Accuracy: 0.3939\n",
      "epoch: 1, step: 670, training loss: 2.1955888271331787, testing loss: 1.9320613145828247\n",
      "Accuracy: 0.3103\n",
      "epoch: 1, step: 680, training loss: 2.1205108165740967, testing loss: 2.1710939407348633\n",
      "Accuracy: 0.2857\n",
      "epoch: 1, step: 690, training loss: 2.073533773422241, testing loss: 3.5362563133239746\n",
      "Accuracy: 0.4375\n",
      "epoch: 1, step: 700, training loss: 1.7962123155593872, testing loss: 4.396007537841797\n",
      "Accuracy: 0.3529\n",
      "epoch: 1, step: 710, training loss: 1.9948688745498657, testing loss: 1.9317841529846191\n",
      "Accuracy: 0.1923\n",
      "epoch: 1, step: 720, training loss: 1.881363868713379, testing loss: 1.752360224723816\n",
      "Accuracy: 0.3171\n",
      "epoch: 1, step: 730, training loss: 1.9670639038085938, testing loss: 1.8642184734344482\n",
      "Accuracy: 0.2632\n",
      "epoch: 1, step: 740, training loss: 2.026939630508423, testing loss: 1.7575687170028687\n",
      "Accuracy: 0.2308\n",
      "epoch: 1, step: 750, training loss: 1.991499900817871, testing loss: 1.7409075498580933\n",
      "Accuracy: 0.3704\n",
      "epoch: 1, step: 760, training loss: 2.0275042057037354, testing loss: 1.7399230003356934\n",
      "Accuracy: 0.3889\n",
      "epoch: 1, step: 770, training loss: 1.6376006603240967, testing loss: 1.6663345098495483\n",
      "Accuracy: 0.2500\n",
      "epoch: 1, step: 780, training loss: 1.8140665292739868, testing loss: 1.3642091751098633\n",
      "Accuracy: 0.3200\n",
      "epoch: 1, step: 790, training loss: 1.5963525772094727, testing loss: 1.3889566659927368\n",
      "Accuracy: 0.5143\n",
      "epoch: 1, step: 800, training loss: 1.919456958770752, testing loss: 1.6130061149597168\n",
      "Accuracy: 0.4324\n",
      "epoch: 1, step: 810, training loss: 2.1166791915893555, testing loss: 2.082913637161255\n",
      "Accuracy: 0.2973\n",
      "epoch: 1, step: 820, training loss: 1.8861241340637207, testing loss: 1.9119625091552734\n",
      "Accuracy: 0.3636\n",
      "epoch: 1, step: 830, training loss: 1.7746096849441528, testing loss: 1.9011205434799194\n",
      "Accuracy: 0.3889\n",
      "epoch: 1, step: 840, training loss: 1.6469897031784058, testing loss: 1.9734054803848267\n",
      "Accuracy: 0.2647\n",
      "epoch: 1, step: 850, training loss: 1.8415919542312622, testing loss: 1.7629597187042236\n",
      "Accuracy: 0.3448\n",
      "epoch: 1, step: 860, training loss: 1.7601240873336792, testing loss: 1.5460747480392456\n",
      "Accuracy: 0.3125\n",
      "epoch: 1, step: 870, training loss: 1.6097745895385742, testing loss: 1.4718834161758423\n",
      "Accuracy: 0.3438\n",
      "epoch: 1, step: 880, training loss: 2.244814872741699, testing loss: 1.785725474357605\n",
      "Accuracy: 0.2857\n",
      "epoch: 1, step: 890, training loss: 1.909894585609436, testing loss: 1.7890796661376953\n",
      "Accuracy: 0.3750\n",
      "epoch: 1, step: 900, training loss: 1.9112282991409302, testing loss: 1.7171281576156616\n",
      "Accuracy: 0.3824\n",
      "epoch: 1, step: 910, training loss: 1.6765549182891846, testing loss: 1.8604753017425537\n",
      "Accuracy: 0.3095\n",
      "epoch: 1, step: 920, training loss: 1.4182883501052856, testing loss: 1.9014606475830078\n",
      "Accuracy: 0.2333\n",
      "epoch: 1, step: 930, training loss: 1.660286545753479, testing loss: 1.512223243713379\n",
      "Accuracy: 0.5714\n",
      "epoch: 1, step: 940, training loss: 1.839257836341858, testing loss: 1.8758116960525513\n",
      "Accuracy: 0.3548\n",
      "epoch: 1, step: 950, training loss: 1.555676817893982, testing loss: 2.1195871829986572\n",
      "Accuracy: 0.3000\n",
      "epoch: 1, step: 960, training loss: 1.9746016263961792, testing loss: 2.1431100368499756\n",
      "Accuracy: 0.2121\n",
      "epoch: 1, step: 970, training loss: 1.9622166156768799, testing loss: 1.7710705995559692\n",
      "Accuracy: 0.3421\n",
      "epoch: 1, step: 980, training loss: 1.573300838470459, testing loss: 1.732372760772705\n",
      "Accuracy: 0.3333\n",
      "epoch: 1, step: 990, training loss: 1.5370227098464966, testing loss: 1.833540439605713\n",
      "Accuracy: 0.3030\n",
      "epoch: 1, step: 1000, training loss: 1.6442680358886719, testing loss: 1.9729291200637817\n",
      "Accuracy: 0.4167\n",
      "epoch: 2, step: 10, training loss: 1.576412320137024, testing loss: 1.6181551218032837\n",
      "Accuracy: 0.4483\n",
      "epoch: 2, step: 20, training loss: 1.5087212324142456, testing loss: 4.683204174041748\n",
      "Accuracy: 0.4444\n",
      "epoch: 2, step: 30, training loss: 1.6371936798095703, testing loss: 1.8222148418426514\n",
      "Accuracy: 0.3939\n",
      "epoch: 2, step: 40, training loss: 2.2526421546936035, testing loss: 1.7624772787094116\n",
      "Accuracy: 0.4800\n",
      "epoch: 2, step: 50, training loss: 1.5300058126449585, testing loss: 1.7422950267791748\n",
      "Accuracy: 0.4722\n",
      "epoch: 2, step: 60, training loss: 1.677489161491394, testing loss: 1.9106407165527344\n",
      "Accuracy: 0.3704\n",
      "epoch: 2, step: 70, training loss: 1.427880048751831, testing loss: 2.0906474590301514\n",
      "Accuracy: 0.3667\n",
      "epoch: 2, step: 80, training loss: 1.7071254253387451, testing loss: 2.1850290298461914\n",
      "Accuracy: 0.3478\n",
      "epoch: 2, step: 90, training loss: 1.6583619117736816, testing loss: 1.5073018074035645\n",
      "Accuracy: 0.4516\n",
      "epoch: 2, step: 100, training loss: 1.592677354812622, testing loss: 1.5884032249450684\n",
      "Accuracy: 0.4848\n",
      "epoch: 2, step: 110, training loss: 1.5751439332962036, testing loss: 1.6530641317367554\n",
      "Accuracy: 0.3611\n",
      "epoch: 2, step: 120, training loss: 1.5848393440246582, testing loss: 1.511670708656311\n",
      "Accuracy: 0.3824\n",
      "epoch: 2, step: 130, training loss: 1.7165406942367554, testing loss: 1.8544344902038574\n",
      "Accuracy: 0.3667\n",
      "epoch: 2, step: 140, training loss: 1.6610878705978394, testing loss: 1.8189144134521484\n",
      "Accuracy: 0.4000\n",
      "epoch: 2, step: 150, training loss: 1.769234538078308, testing loss: 1.9099091291427612\n",
      "Accuracy: 0.3590\n",
      "epoch: 2, step: 160, training loss: 1.8438001871109009, testing loss: 2.344796657562256\n",
      "Accuracy: 0.2258\n",
      "epoch: 2, step: 170, training loss: 1.9166332483291626, testing loss: 1.9825254678726196\n",
      "Accuracy: 0.2424\n",
      "epoch: 2, step: 180, training loss: 1.8202605247497559, testing loss: 1.4070661067962646\n",
      "Accuracy: 0.5714\n",
      "epoch: 2, step: 190, training loss: 1.9555257558822632, testing loss: 1.489520788192749\n",
      "Accuracy: 0.4615\n",
      "epoch: 2, step: 200, training loss: 1.9022427797317505, testing loss: 1.6608835458755493\n",
      "Accuracy: 0.4062\n",
      "epoch: 2, step: 210, training loss: 1.6688348054885864, testing loss: 1.531653881072998\n",
      "Accuracy: 0.4444\n",
      "epoch: 2, step: 220, training loss: 1.5293697118759155, testing loss: 1.771683931350708\n",
      "Accuracy: 0.4000\n",
      "epoch: 2, step: 230, training loss: 1.6758196353912354, testing loss: 1.9121061563491821\n",
      "Accuracy: 0.3611\n",
      "epoch: 2, step: 240, training loss: 1.5618245601654053, testing loss: 1.9662353992462158\n",
      "Accuracy: 0.3200\n",
      "epoch: 2, step: 250, training loss: 1.5492358207702637, testing loss: 1.8969639539718628\n",
      "Accuracy: 0.3226\n",
      "epoch: 2, step: 260, training loss: 1.9685577154159546, testing loss: 1.6710258722305298\n",
      "Accuracy: 0.3902\n",
      "epoch: 2, step: 270, training loss: 1.7224931716918945, testing loss: 1.6188585758209229\n",
      "Accuracy: 0.4872\n",
      "epoch: 2, step: 280, training loss: 1.7139219045639038, testing loss: 1.6732555627822876\n",
      "Accuracy: 0.5526\n",
      "epoch: 2, step: 290, training loss: 1.58967125415802, testing loss: 1.8338626623153687\n",
      "Accuracy: 0.2903\n",
      "epoch: 2, step: 300, training loss: 1.6483955383300781, testing loss: 1.769594669342041\n",
      "Accuracy: 0.4000\n",
      "epoch: 2, step: 310, training loss: 1.622024655342102, testing loss: 1.7240173816680908\n",
      "Accuracy: 0.4483\n",
      "epoch: 2, step: 320, training loss: 1.8346734046936035, testing loss: 2.0528688430786133\n",
      "Accuracy: 0.3793\n",
      "epoch: 2, step: 330, training loss: 1.5339943170547485, testing loss: 1.8640334606170654\n",
      "Accuracy: 0.2903\n",
      "epoch: 2, step: 340, training loss: 1.736130714416504, testing loss: 1.5846037864685059\n",
      "Accuracy: 0.3704\n",
      "epoch: 2, step: 350, training loss: 1.7677438259124756, testing loss: 1.9759440422058105\n",
      "Accuracy: 0.3333\n",
      "epoch: 2, step: 360, training loss: 1.8958059549331665, testing loss: 1.831353783607483\n",
      "Accuracy: 0.2727\n",
      "epoch: 2, step: 370, training loss: 1.9050766229629517, testing loss: 1.7913380861282349\n",
      "Accuracy: 0.4054\n",
      "epoch: 2, step: 380, training loss: 1.7119334936141968, testing loss: 1.4780806303024292\n",
      "Accuracy: 0.5333\n",
      "epoch: 2, step: 390, training loss: 1.8017401695251465, testing loss: 1.6023613214492798\n",
      "Accuracy: 0.4848\n",
      "epoch: 2, step: 400, training loss: 1.796015739440918, testing loss: 1.724979281425476\n",
      "Accuracy: 0.3125\n",
      "epoch: 2, step: 410, training loss: 1.6187278032302856, testing loss: 1.525959849357605\n",
      "Accuracy: 0.3438\n",
      "epoch: 2, step: 420, training loss: 1.2344998121261597, testing loss: 2.026365041732788\n",
      "Accuracy: 0.3000\n",
      "epoch: 2, step: 430, training loss: 1.6697067022323608, testing loss: 1.685224175453186\n",
      "Accuracy: 0.4815\n",
      "epoch: 2, step: 440, training loss: 1.7310627698898315, testing loss: 2.1409966945648193\n",
      "Accuracy: 0.3750\n",
      "epoch: 2, step: 450, training loss: 1.9607090950012207, testing loss: 2.1180689334869385\n",
      "Accuracy: 0.4333\n",
      "epoch: 2, step: 460, training loss: 1.5806725025177002, testing loss: 1.7299339771270752\n",
      "Accuracy: 0.3793\n",
      "epoch: 2, step: 470, training loss: 1.6335266828536987, testing loss: 1.24478018283844\n",
      "Accuracy: 0.5758\n",
      "epoch: 2, step: 480, training loss: 2.088982343673706, testing loss: 2.0338528156280518\n",
      "Accuracy: 0.4516\n",
      "epoch: 2, step: 490, training loss: 1.815242886543274, testing loss: 1.8022974729537964\n",
      "Accuracy: 0.2424\n",
      "epoch: 2, step: 500, training loss: 1.682490587234497, testing loss: 1.9196979999542236\n",
      "Accuracy: 0.3409\n",
      "epoch: 2, step: 510, training loss: 1.5405824184417725, testing loss: 1.5958210229873657\n",
      "Accuracy: 0.3871\n",
      "epoch: 2, step: 520, training loss: 1.3929932117462158, testing loss: 1.7426321506500244\n",
      "Accuracy: 0.3235\n",
      "epoch: 2, step: 530, training loss: 1.6348243951797485, testing loss: 1.4557985067367554\n",
      "Accuracy: 0.4500\n",
      "epoch: 2, step: 540, training loss: 1.461207389831543, testing loss: 1.5676586627960205\n",
      "Accuracy: 0.4250\n",
      "epoch: 2, step: 550, training loss: 1.6631889343261719, testing loss: 1.3732870817184448\n",
      "Accuracy: 0.3200\n",
      "epoch: 2, step: 560, training loss: 1.6054481267929077, testing loss: 1.703898549079895\n",
      "Accuracy: 0.5143\n",
      "epoch: 2, step: 570, training loss: 1.7249319553375244, testing loss: 1.8300951719284058\n",
      "Accuracy: 0.3125\n",
      "epoch: 2, step: 580, training loss: 1.7252548933029175, testing loss: 1.167207956314087\n",
      "Accuracy: 0.4400\n",
      "epoch: 2, step: 590, training loss: 1.7859472036361694, testing loss: 1.7161718606948853\n",
      "Accuracy: 0.4857\n",
      "epoch: 2, step: 600, training loss: 1.846470832824707, testing loss: 1.4208297729492188\n",
      "Accuracy: 0.3438\n",
      "epoch: 2, step: 610, training loss: 1.4644721746444702, testing loss: 1.5973502397537231\n",
      "Accuracy: 0.4318\n",
      "epoch: 2, step: 620, training loss: 1.4870903491973877, testing loss: 1.7632219791412354\n",
      "Accuracy: 0.3636\n",
      "epoch: 2, step: 630, training loss: 1.277116060256958, testing loss: 1.4659621715545654\n",
      "Accuracy: 0.3929\n",
      "epoch: 2, step: 640, training loss: 1.5728559494018555, testing loss: 1.7270746231079102\n",
      "Accuracy: 0.4242\n",
      "epoch: 2, step: 650, training loss: 1.6688340902328491, testing loss: 1.407358169555664\n",
      "Accuracy: 0.5714\n",
      "epoch: 2, step: 660, training loss: 1.553114414215088, testing loss: 1.8060929775238037\n",
      "Accuracy: 0.3793\n",
      "epoch: 2, step: 670, training loss: 1.8463624715805054, testing loss: 1.6787091493606567\n",
      "Accuracy: 0.3929\n",
      "epoch: 2, step: 680, training loss: 2.0789196491241455, testing loss: 4.418704032897949\n",
      "Accuracy: 0.3636\n",
      "epoch: 2, step: 690, training loss: 1.7499809265136719, testing loss: 1.7885429859161377\n",
      "Accuracy: 0.3793\n",
      "epoch: 2, step: 700, training loss: 1.6422194242477417, testing loss: 1.6987262964248657\n",
      "Accuracy: 0.3103\n",
      "epoch: 2, step: 710, training loss: 1.601313829421997, testing loss: 1.9015825986862183\n",
      "Accuracy: 0.2333\n",
      "epoch: 2, step: 720, training loss: 1.6836748123168945, testing loss: 2.0310065746307373\n",
      "Accuracy: 0.3750\n",
      "epoch: 2, step: 730, training loss: 1.791853666305542, testing loss: 1.6819088459014893\n",
      "Accuracy: 0.4865\n",
      "epoch: 2, step: 740, training loss: 1.7097394466400146, testing loss: 1.816740870475769\n",
      "Accuracy: 0.4062\n",
      "epoch: 2, step: 750, training loss: 1.7248696088790894, testing loss: 1.6747938394546509\n",
      "Accuracy: 0.4194\n",
      "epoch: 2, step: 760, training loss: 1.547379493713379, testing loss: 1.8552628755569458\n",
      "Accuracy: 0.5357\n",
      "epoch: 2, step: 770, training loss: 1.687847375869751, testing loss: 1.5485799312591553\n",
      "Accuracy: 0.2308\n",
      "epoch: 2, step: 780, training loss: 1.5454065799713135, testing loss: 1.6040822267532349\n",
      "Accuracy: 0.2308\n",
      "epoch: 2, step: 790, training loss: 2.149587869644165, testing loss: 1.7470979690551758\n",
      "Accuracy: 0.4118\n",
      "epoch: 2, step: 800, training loss: 1.961083173751831, testing loss: 1.8704160451889038\n",
      "Accuracy: 0.3667\n",
      "epoch: 2, step: 810, training loss: 1.6837619543075562, testing loss: 1.6285480260849\n",
      "Accuracy: 0.4865\n",
      "epoch: 2, step: 820, training loss: 1.6479042768478394, testing loss: 1.9468375444412231\n",
      "Accuracy: 0.3125\n",
      "epoch: 2, step: 830, training loss: 1.496915340423584, testing loss: 1.5028682947158813\n",
      "Accuracy: 0.4688\n",
      "epoch: 2, step: 840, training loss: 1.6879749298095703, testing loss: 1.301454782485962\n",
      "Accuracy: 0.5652\n",
      "epoch: 2, step: 850, training loss: 1.5531753301620483, testing loss: 1.9168680906295776\n",
      "Accuracy: 0.3750\n",
      "epoch: 2, step: 860, training loss: 1.75421941280365, testing loss: 1.6475218534469604\n",
      "Accuracy: 0.4062\n",
      "epoch: 2, step: 870, training loss: 1.9222787618637085, testing loss: 1.611197829246521\n",
      "Accuracy: 0.3415\n",
      "epoch: 2, step: 880, training loss: 1.7302285432815552, testing loss: 1.6866053342819214\n",
      "Accuracy: 0.4545\n",
      "epoch: 2, step: 890, training loss: 1.4725548028945923, testing loss: 1.7594215869903564\n",
      "Accuracy: 0.3571\n",
      "epoch: 2, step: 900, training loss: 1.7167093753814697, testing loss: 1.6698081493377686\n",
      "Accuracy: 0.4286\n",
      "epoch: 2, step: 910, training loss: 1.6844029426574707, testing loss: 1.7054795026779175\n",
      "Accuracy: 0.4688\n",
      "epoch: 2, step: 920, training loss: 1.925842523574829, testing loss: 1.904953956604004\n",
      "Accuracy: 0.4516\n",
      "epoch: 2, step: 930, training loss: 1.714935541152954, testing loss: 1.7694376707077026\n",
      "Accuracy: 0.5455\n",
      "epoch: 2, step: 940, training loss: 1.7243238687515259, testing loss: 1.7850836515426636\n",
      "Accuracy: 0.3571\n",
      "epoch: 2, step: 950, training loss: 1.684169888496399, testing loss: 1.8785196542739868\n",
      "Accuracy: 0.3125\n",
      "epoch: 2, step: 960, training loss: 1.543627381324768, testing loss: 1.5654494762420654\n",
      "Accuracy: 0.3784\n",
      "epoch: 2, step: 970, training loss: 1.4518924951553345, testing loss: 1.9413390159606934\n",
      "Accuracy: 0.1667\n",
      "epoch: 2, step: 980, training loss: 1.6923456192016602, testing loss: 1.6133246421813965\n",
      "Accuracy: 0.5143\n",
      "epoch: 2, step: 990, training loss: 1.7438764572143555, testing loss: 1.6267125606536865\n",
      "Accuracy: 0.4571\n",
      "epoch: 2, step: 1000, training loss: 1.5329123735427856, testing loss: 1.6094670295715332\n",
      "Accuracy: 0.2800\n",
      "epoch: 3, step: 10, training loss: 1.6844514608383179, testing loss: 1.7041884660720825\n",
      "Accuracy: 0.2812\n",
      "epoch: 3, step: 20, training loss: 1.6811470985412598, testing loss: 1.5361015796661377\n",
      "Accuracy: 0.4167\n",
      "epoch: 3, step: 30, training loss: 1.4468392133712769, testing loss: 1.6051443815231323\n",
      "Accuracy: 0.4333\n",
      "epoch: 3, step: 40, training loss: 1.956131100654602, testing loss: 1.5703065395355225\n",
      "Accuracy: 0.5625\n",
      "epoch: 3, step: 50, training loss: 1.501821756362915, testing loss: 1.4520466327667236\n",
      "Accuracy: 0.3793\n",
      "epoch: 3, step: 60, training loss: 1.9470911026000977, testing loss: 2.0044875144958496\n",
      "Accuracy: 0.3636\n",
      "epoch: 3, step: 70, training loss: 2.0261785984039307, testing loss: 2.0931708812713623\n",
      "Accuracy: 0.2895\n",
      "epoch: 3, step: 80, training loss: 1.964401125907898, testing loss: 2.040691375732422\n",
      "Accuracy: 0.4242\n",
      "epoch: 3, step: 90, training loss: 1.614515781402588, testing loss: 1.6769979000091553\n",
      "Accuracy: 0.5714\n",
      "epoch: 3, step: 100, training loss: 1.794893741607666, testing loss: 1.239162564277649\n",
      "Accuracy: 0.5882\n",
      "epoch: 3, step: 110, training loss: 1.5557018518447876, testing loss: 1.6872366666793823\n",
      "Accuracy: 0.4062\n",
      "epoch: 3, step: 120, training loss: 1.6345363855361938, testing loss: 1.6772233247756958\n",
      "Accuracy: 0.3750\n",
      "epoch: 3, step: 130, training loss: 1.7765153646469116, testing loss: 1.4847348928451538\n",
      "Accuracy: 0.5769\n",
      "epoch: 3, step: 140, training loss: 1.617846131324768, testing loss: 1.7827205657958984\n",
      "Accuracy: 0.3929\n",
      "epoch: 3, step: 150, training loss: 1.8893076181411743, testing loss: 1.4789190292358398\n",
      "Accuracy: 0.5185\n",
      "epoch: 3, step: 160, training loss: 1.7358767986297607, testing loss: 1.5982558727264404\n",
      "Accuracy: 0.4348\n",
      "epoch: 3, step: 170, training loss: 1.4919668436050415, testing loss: 1.7664737701416016\n",
      "Accuracy: 0.3824\n",
      "epoch: 3, step: 180, training loss: 1.8469092845916748, testing loss: 1.5749238729476929\n",
      "Accuracy: 0.4839\n",
      "epoch: 3, step: 190, training loss: 1.733249545097351, testing loss: 1.6597126722335815\n",
      "Accuracy: 0.4062\n",
      "epoch: 3, step: 200, training loss: 1.4728471040725708, testing loss: 1.721492052078247\n",
      "Accuracy: 0.4571\n",
      "epoch: 3, step: 210, training loss: 1.786031723022461, testing loss: 2.046481132507324\n",
      "Accuracy: 0.2564\n",
      "epoch: 3, step: 220, training loss: 1.9584753513336182, testing loss: 2.183884382247925\n",
      "Accuracy: 0.3824\n",
      "epoch: 3, step: 230, training loss: 1.5372205972671509, testing loss: 1.572167158126831\n",
      "Accuracy: 0.4706\n",
      "epoch: 3, step: 240, training loss: 1.7122279405593872, testing loss: 1.5802123546600342\n",
      "Accuracy: 0.4828\n",
      "epoch: 3, step: 250, training loss: 1.4571506977081299, testing loss: 1.8412498235702515\n",
      "Accuracy: 0.3684\n",
      "epoch: 3, step: 260, training loss: 1.5120753049850464, testing loss: 1.5488101243972778\n",
      "Accuracy: 0.5250\n",
      "epoch: 3, step: 270, training loss: 1.562050461769104, testing loss: 1.4500876665115356\n",
      "Accuracy: 0.4194\n",
      "epoch: 3, step: 280, training loss: 1.5571327209472656, testing loss: 1.470734715461731\n",
      "Accuracy: 0.4000\n",
      "epoch: 3, step: 290, training loss: 1.8617182970046997, testing loss: 1.3953962326049805\n",
      "Accuracy: 0.5250\n",
      "epoch: 3, step: 300, training loss: 1.682584285736084, testing loss: 1.6579171419143677\n",
      "Accuracy: 0.3750\n",
      "epoch: 3, step: 310, training loss: 1.549471378326416, testing loss: 1.6017414331436157\n",
      "Accuracy: 0.4054\n",
      "epoch: 3, step: 320, training loss: 1.4165934324264526, testing loss: 1.8327099084854126\n",
      "Accuracy: 0.2414\n",
      "epoch: 3, step: 330, training loss: 1.5350189208984375, testing loss: 1.711578607559204\n",
      "Accuracy: 0.5333\n",
      "epoch: 3, step: 340, training loss: 1.5609179735183716, testing loss: 1.6165928840637207\n",
      "Accuracy: 0.4167\n",
      "epoch: 3, step: 350, training loss: 2.0731923580169678, testing loss: 1.5520284175872803\n",
      "Accuracy: 0.5806\n",
      "epoch: 3, step: 360, training loss: 1.5802583694458008, testing loss: 1.7877271175384521\n",
      "Accuracy: 0.4483\n",
      "epoch: 3, step: 370, training loss: 1.7126023769378662, testing loss: 1.7626965045928955\n",
      "Accuracy: 0.4194\n",
      "epoch: 3, step: 380, training loss: 1.3490232229232788, testing loss: 1.5296167135238647\n",
      "Accuracy: 0.3939\n",
      "epoch: 3, step: 390, training loss: 1.6449437141418457, testing loss: 1.6430548429489136\n",
      "Accuracy: 0.4865\n",
      "epoch: 3, step: 400, training loss: 1.646743655204773, testing loss: 1.8799173831939697\n",
      "Accuracy: 0.3571\n",
      "epoch: 3, step: 410, training loss: 1.8392094373703003, testing loss: 1.9832446575164795\n",
      "Accuracy: 0.3256\n",
      "epoch: 3, step: 420, training loss: 1.8185795545578003, testing loss: 1.5768487453460693\n",
      "Accuracy: 0.3714\n",
      "epoch: 3, step: 430, training loss: 1.804340124130249, testing loss: 1.8982417583465576\n",
      "Accuracy: 0.3214\n",
      "epoch: 3, step: 440, training loss: 1.518135666847229, testing loss: 1.9773857593536377\n",
      "Accuracy: 0.3824\n",
      "epoch: 3, step: 450, training loss: 1.5402132272720337, testing loss: 2.0931601524353027\n",
      "Accuracy: 0.3077\n",
      "epoch: 3, step: 460, training loss: 1.794539213180542, testing loss: 1.5122817754745483\n",
      "Accuracy: 0.4286\n",
      "epoch: 3, step: 470, training loss: 1.6318882703781128, testing loss: 1.58174729347229\n",
      "Accuracy: 0.3056\n",
      "epoch: 3, step: 480, training loss: 1.759324550628662, testing loss: 1.461728811264038\n",
      "Accuracy: 0.5000\n",
      "epoch: 3, step: 490, training loss: 1.8325459957122803, testing loss: 1.7026498317718506\n",
      "Accuracy: 0.3462\n",
      "epoch: 3, step: 500, training loss: 1.5453141927719116, testing loss: 1.8233938217163086\n",
      "Accuracy: 0.3824\n",
      "epoch: 3, step: 510, training loss: 1.78109610080719, testing loss: 1.6242237091064453\n",
      "Accuracy: 0.4857\n",
      "epoch: 3, step: 520, training loss: 1.6404372453689575, testing loss: 1.6459429264068604\n",
      "Accuracy: 0.4634\n",
      "epoch: 3, step: 530, training loss: 1.5098292827606201, testing loss: 1.4298853874206543\n",
      "Accuracy: 0.4333\n",
      "epoch: 3, step: 540, training loss: 1.6467158794403076, testing loss: 1.4753791093826294\n",
      "Accuracy: 0.5000\n",
      "epoch: 3, step: 550, training loss: 1.5687100887298584, testing loss: 1.407863974571228\n",
      "Accuracy: 0.4516\n",
      "epoch: 3, step: 560, training loss: 1.5420693159103394, testing loss: 1.7752934694290161\n",
      "Accuracy: 0.3333\n",
      "epoch: 3, step: 570, training loss: 1.609790325164795, testing loss: 1.5021405220031738\n",
      "Accuracy: 0.4444\n",
      "epoch: 3, step: 580, training loss: 1.4010331630706787, testing loss: 2.047354221343994\n",
      "Accuracy: 0.3750\n",
      "epoch: 3, step: 590, training loss: 1.6639416217803955, testing loss: 1.5209916830062866\n",
      "Accuracy: 0.4800\n",
      "epoch: 3, step: 600, training loss: 1.5598832368850708, testing loss: 1.75986909866333\n",
      "Accuracy: 0.3611\n",
      "epoch: 3, step: 610, training loss: 1.7257835865020752, testing loss: 1.587283968925476\n",
      "Accuracy: 0.3226\n",
      "epoch: 3, step: 620, training loss: 1.6641228199005127, testing loss: 1.796191692352295\n",
      "Accuracy: 0.3750\n",
      "epoch: 3, step: 630, training loss: 1.8002179861068726, testing loss: 1.6127408742904663\n",
      "Accuracy: 0.4444\n",
      "epoch: 3, step: 640, training loss: 1.8544285297393799, testing loss: 1.945041298866272\n",
      "Accuracy: 0.3750\n",
      "epoch: 3, step: 650, training loss: 1.3052899837493896, testing loss: 1.5587882995605469\n",
      "Accuracy: 0.3939\n",
      "epoch: 3, step: 660, training loss: 1.8985252380371094, testing loss: 1.8908685445785522\n",
      "Accuracy: 0.4500\n",
      "epoch: 3, step: 670, training loss: 1.5579198598861694, testing loss: 1.6986879110336304\n",
      "Accuracy: 0.3929\n",
      "epoch: 3, step: 680, training loss: 1.7810194492340088, testing loss: 1.719604730606079\n",
      "Accuracy: 0.4242\n",
      "epoch: 3, step: 690, training loss: 1.976946234703064, testing loss: 1.7119337320327759\n",
      "Accuracy: 0.4516\n",
      "epoch: 3, step: 700, training loss: 1.7590570449829102, testing loss: 1.8846023082733154\n",
      "Accuracy: 0.3529\n",
      "epoch: 3, step: 710, training loss: 1.758851408958435, testing loss: 1.7732346057891846\n",
      "Accuracy: 0.3333\n",
      "epoch: 3, step: 720, training loss: 1.5885814428329468, testing loss: 1.5546655654907227\n",
      "Accuracy: 0.4815\n",
      "epoch: 3, step: 730, training loss: 1.530470848083496, testing loss: 1.8620668649673462\n",
      "Accuracy: 0.2258\n",
      "epoch: 3, step: 740, training loss: 1.5877647399902344, testing loss: 1.4966912269592285\n",
      "Accuracy: 0.4483\n",
      "epoch: 3, step: 750, training loss: 1.6979353427886963, testing loss: 1.8106896877288818\n",
      "Accuracy: 0.2500\n",
      "epoch: 3, step: 760, training loss: 1.5483663082122803, testing loss: 1.6693373918533325\n",
      "Accuracy: 0.4516\n",
      "epoch: 3, step: 770, training loss: 1.5589708089828491, testing loss: 1.8285572528839111\n",
      "Accuracy: 0.4857\n",
      "epoch: 3, step: 780, training loss: 1.6993144750595093, testing loss: 1.4708826541900635\n",
      "Accuracy: 0.4571\n",
      "epoch: 3, step: 790, training loss: 1.7348957061767578, testing loss: 1.4883301258087158\n",
      "Accuracy: 0.4000\n",
      "epoch: 3, step: 800, training loss: 1.6009689569473267, testing loss: 2.0503103733062744\n",
      "Accuracy: 0.3438\n",
      "epoch: 3, step: 810, training loss: 1.8893910646438599, testing loss: 1.6221891641616821\n",
      "Accuracy: 0.3684\n",
      "epoch: 3, step: 820, training loss: 1.5624656677246094, testing loss: 1.3709969520568848\n",
      "Accuracy: 0.4231\n",
      "epoch: 3, step: 830, training loss: 1.9504364728927612, testing loss: 1.8016242980957031\n",
      "Accuracy: 0.3333\n",
      "epoch: 3, step: 840, training loss: 1.6341397762298584, testing loss: 1.4350312948226929\n",
      "Accuracy: 0.5000\n",
      "epoch: 3, step: 850, training loss: 1.6642743349075317, testing loss: 1.6360490322113037\n",
      "Accuracy: 0.3929\n",
      "epoch: 3, step: 860, training loss: 1.5536434650421143, testing loss: 1.6794594526290894\n",
      "Accuracy: 0.1875\n",
      "epoch: 3, step: 870, training loss: 1.957802414894104, testing loss: 1.8464717864990234\n",
      "Accuracy: 0.4318\n",
      "epoch: 3, step: 880, training loss: 2.007399797439575, testing loss: 2.0986759662628174\n",
      "Accuracy: 0.4000\n",
      "epoch: 3, step: 890, training loss: 1.518088936805725, testing loss: 2.3090932369232178\n",
      "Accuracy: 0.3182\n",
      "epoch: 3, step: 900, training loss: 1.7003792524337769, testing loss: 1.6885755062103271\n",
      "Accuracy: 0.4595\n",
      "epoch: 3, step: 910, training loss: 1.6366904973983765, testing loss: 1.4505512714385986\n",
      "Accuracy: 0.3235\n",
      "epoch: 3, step: 920, training loss: 2.0449531078338623, testing loss: 1.421777606010437\n",
      "Accuracy: 0.4839\n",
      "epoch: 3, step: 930, training loss: 1.9623563289642334, testing loss: 1.9275976419448853\n",
      "Accuracy: 0.3929\n",
      "epoch: 3, step: 940, training loss: 1.72498619556427, testing loss: 1.387214183807373\n",
      "Accuracy: 0.4722\n",
      "epoch: 3, step: 950, training loss: 1.7335964441299438, testing loss: 1.519852638244629\n",
      "Accuracy: 0.3871\n",
      "epoch: 3, step: 960, training loss: 1.6256194114685059, testing loss: 1.9166828393936157\n",
      "Accuracy: 0.3864\n",
      "epoch: 3, step: 970, training loss: 1.685158133506775, testing loss: 1.7141947746276855\n",
      "Accuracy: 0.3889\n",
      "epoch: 3, step: 980, training loss: 1.6955772638320923, testing loss: 1.4512381553649902\n",
      "Accuracy: 0.3333\n",
      "epoch: 3, step: 990, training loss: 1.603366732597351, testing loss: 1.7316572666168213\n",
      "Accuracy: 0.3929\n",
      "epoch: 3, step: 1000, training loss: 1.583234429359436, testing loss: 1.6585345268249512\n",
      "Accuracy: 0.5806\n",
      "epoch: 4, step: 10, training loss: 1.813716173171997, testing loss: 1.9264224767684937\n",
      "Accuracy: 0.3871\n",
      "epoch: 4, step: 20, training loss: 1.9031364917755127, testing loss: 1.4903478622436523\n",
      "Accuracy: 0.3333\n",
      "epoch: 4, step: 30, training loss: 1.432707667350769, testing loss: 1.7050973176956177\n",
      "Accuracy: 0.4324\n",
      "epoch: 4, step: 40, training loss: 1.6424190998077393, testing loss: 1.8794149160385132\n",
      "Accuracy: 0.4138\n",
      "epoch: 4, step: 50, training loss: 1.5913654565811157, testing loss: 1.5416271686553955\n",
      "Accuracy: 0.4595\n",
      "epoch: 4, step: 60, training loss: 1.6816507577896118, testing loss: 1.7122787237167358\n",
      "Accuracy: 0.3158\n",
      "epoch: 4, step: 70, training loss: 1.6161316633224487, testing loss: 1.8266679048538208\n",
      "Accuracy: 0.4815\n",
      "epoch: 4, step: 80, training loss: 1.6726590394973755, testing loss: 1.5405749082565308\n",
      "Accuracy: 0.4242\n",
      "epoch: 4, step: 90, training loss: 1.5088998079299927, testing loss: 1.5518466234207153\n",
      "Accuracy: 0.4444\n",
      "epoch: 4, step: 100, training loss: 1.8632451295852661, testing loss: 1.9358402490615845\n",
      "Accuracy: 0.2500\n",
      "epoch: 4, step: 110, training loss: 1.5311189889907837, testing loss: 1.6423200368881226\n",
      "Accuracy: 0.5000\n",
      "epoch: 4, step: 120, training loss: 1.8053172826766968, testing loss: 1.6093275547027588\n",
      "Accuracy: 0.3214\n",
      "epoch: 4, step: 130, training loss: 1.38857901096344, testing loss: 1.5834873914718628\n",
      "Accuracy: 0.3846\n",
      "epoch: 4, step: 140, training loss: 1.6459994316101074, testing loss: 1.3962382078170776\n",
      "Accuracy: 0.4167\n",
      "epoch: 4, step: 150, training loss: 1.8089462518692017, testing loss: 1.5712230205535889\n",
      "Accuracy: 0.3611\n",
      "epoch: 4, step: 160, training loss: 1.6539373397827148, testing loss: 1.8418922424316406\n",
      "Accuracy: 0.2593\n",
      "epoch: 4, step: 170, training loss: 1.4396405220031738, testing loss: 2.0210468769073486\n",
      "Accuracy: 0.3636\n",
      "epoch: 4, step: 180, training loss: 1.74937903881073, testing loss: 1.6568732261657715\n",
      "Accuracy: 0.2414\n",
      "epoch: 4, step: 190, training loss: 1.6063506603240967, testing loss: 1.6715598106384277\n",
      "Accuracy: 0.3947\n",
      "epoch: 4, step: 200, training loss: 1.7319248914718628, testing loss: 1.8313719034194946\n",
      "Accuracy: 0.3095\n",
      "epoch: 4, step: 210, training loss: 1.35211181640625, testing loss: 1.9663245677947998\n",
      "Accuracy: 0.3667\n",
      "epoch: 4, step: 220, training loss: 1.6596018075942993, testing loss: 1.7315398454666138\n",
      "Accuracy: 0.4898\n",
      "epoch: 4, step: 230, training loss: 1.729017972946167, testing loss: 1.8858022689819336\n",
      "Accuracy: 0.3600\n",
      "epoch: 4, step: 240, training loss: 1.4964776039123535, testing loss: 1.6680421829223633\n",
      "Accuracy: 0.4828\n",
      "epoch: 4, step: 250, training loss: 1.5163220167160034, testing loss: 1.9700120687484741\n",
      "Accuracy: 0.3421\n",
      "epoch: 4, step: 260, training loss: 1.3968523740768433, testing loss: 1.6867258548736572\n",
      "Accuracy: 0.4074\n",
      "epoch: 4, step: 270, training loss: 1.667254090309143, testing loss: 1.1122562885284424\n",
      "Accuracy: 0.7500\n",
      "epoch: 4, step: 280, training loss: 1.6810286045074463, testing loss: 2.027442693710327\n",
      "Accuracy: 0.2727\n",
      "epoch: 4, step: 290, training loss: 1.7354754209518433, testing loss: 2.013187885284424\n",
      "Accuracy: 0.4688\n",
      "epoch: 4, step: 300, training loss: 1.491036295890808, testing loss: 2.299835681915283\n",
      "Accuracy: 0.2759\n",
      "epoch: 4, step: 310, training loss: 1.7273054122924805, testing loss: 1.8955106735229492\n",
      "Accuracy: 0.4138\n",
      "epoch: 4, step: 320, training loss: 1.6487096548080444, testing loss: 1.7664568424224854\n",
      "Accuracy: 0.3846\n",
      "epoch: 4, step: 330, training loss: 1.7062816619873047, testing loss: 1.5913276672363281\n",
      "Accuracy: 0.5000\n",
      "epoch: 4, step: 340, training loss: 1.7798552513122559, testing loss: 1.408992052078247\n",
      "Accuracy: 0.4545\n",
      "epoch: 4, step: 350, training loss: 1.6340726613998413, testing loss: 1.5828853845596313\n",
      "Accuracy: 0.4595\n",
      "epoch: 4, step: 360, training loss: 1.4224940538406372, testing loss: 1.5506867170333862\n",
      "Accuracy: 0.4667\n",
      "epoch: 4, step: 370, training loss: 1.4884556531906128, testing loss: 1.8172508478164673\n",
      "Accuracy: 0.2571\n",
      "epoch: 4, step: 380, training loss: 1.7576055526733398, testing loss: 1.5621089935302734\n",
      "Accuracy: 0.4857\n",
      "epoch: 4, step: 390, training loss: 1.5415644645690918, testing loss: 2.002620220184326\n",
      "Accuracy: 0.4286\n",
      "epoch: 4, step: 400, training loss: 1.6124892234802246, testing loss: 1.713118076324463\n",
      "Accuracy: 0.4333\n",
      "epoch: 4, step: 410, training loss: 1.6589077711105347, testing loss: 1.647594690322876\n",
      "Accuracy: 0.3939\n",
      "epoch: 4, step: 420, training loss: 1.3868194818496704, testing loss: 1.9488141536712646\n",
      "Accuracy: 0.3611\n",
      "epoch: 4, step: 430, training loss: 1.5969496965408325, testing loss: 1.7449647188186646\n",
      "Accuracy: 0.2500\n",
      "epoch: 4, step: 440, training loss: 1.705520749092102, testing loss: 1.765600562095642\n",
      "Accuracy: 0.3714\n",
      "epoch: 4, step: 450, training loss: 1.46306312084198, testing loss: 1.7150391340255737\n",
      "Accuracy: 0.3636\n",
      "epoch: 4, step: 460, training loss: 1.7486168146133423, testing loss: 2.288271188735962\n",
      "Accuracy: 0.2889\n",
      "epoch: 4, step: 470, training loss: 1.4633480310440063, testing loss: 1.7002856731414795\n",
      "Accuracy: 0.4000\n",
      "epoch: 4, step: 480, training loss: 1.7420624494552612, testing loss: 1.689574122428894\n",
      "Accuracy: 0.5312\n",
      "epoch: 4, step: 490, training loss: 1.7093640565872192, testing loss: 2.1486222743988037\n",
      "Accuracy: 0.3617\n",
      "epoch: 4, step: 500, training loss: 1.970137596130371, testing loss: 1.7930552959442139\n",
      "Accuracy: 0.2903\n",
      "epoch: 4, step: 510, training loss: 1.6288608312606812, testing loss: 1.7217669486999512\n",
      "Accuracy: 0.3714\n",
      "epoch: 4, step: 520, training loss: 1.490671992301941, testing loss: 1.834897518157959\n",
      "Accuracy: 0.3438\n",
      "epoch: 4, step: 530, training loss: 1.7131998538970947, testing loss: 1.807143211364746\n",
      "Accuracy: 0.2821\n",
      "epoch: 4, step: 540, training loss: 1.6087753772735596, testing loss: 1.8815481662750244\n",
      "Accuracy: 0.3103\n",
      "epoch: 4, step: 550, training loss: 1.4513797760009766, testing loss: 1.8089137077331543\n",
      "Accuracy: 0.3333\n",
      "epoch: 4, step: 560, training loss: 1.5430524349212646, testing loss: 1.5171458721160889\n",
      "Accuracy: 0.3871\n",
      "epoch: 4, step: 570, training loss: 1.7268717288970947, testing loss: 1.3201775550842285\n",
      "Accuracy: 0.6538\n",
      "epoch: 4, step: 580, training loss: 1.1705249547958374, testing loss: 1.8828074932098389\n",
      "Accuracy: 0.3261\n",
      "epoch: 4, step: 590, training loss: 1.5358946323394775, testing loss: 2.4230997562408447\n",
      "Accuracy: 0.2857\n",
      "epoch: 4, step: 600, training loss: 1.8890653848648071, testing loss: 2.383185863494873\n",
      "Accuracy: 0.2941\n",
      "epoch: 4, step: 610, training loss: 1.8507614135742188, testing loss: 1.6523529291152954\n",
      "Accuracy: 0.4545\n",
      "epoch: 4, step: 620, training loss: 1.895263433456421, testing loss: 1.8507169485092163\n",
      "Accuracy: 0.2286\n",
      "epoch: 4, step: 630, training loss: 1.4924557209014893, testing loss: 1.8008626699447632\n",
      "Accuracy: 0.3333\n",
      "epoch: 4, step: 640, training loss: 1.4555952548980713, testing loss: 1.7099307775497437\n",
      "Accuracy: 0.6000\n",
      "epoch: 4, step: 650, training loss: 1.8597770929336548, testing loss: 1.6414374113082886\n",
      "Accuracy: 0.2759\n",
      "epoch: 4, step: 660, training loss: 1.5497570037841797, testing loss: 1.468549370765686\n",
      "Accuracy: 0.5758\n",
      "epoch: 4, step: 670, training loss: 1.6717270612716675, testing loss: 1.8534592390060425\n",
      "Accuracy: 0.3333\n",
      "epoch: 4, step: 680, training loss: 1.6254334449768066, testing loss: 1.9657803773880005\n",
      "Accuracy: 0.2857\n",
      "epoch: 4, step: 690, training loss: 1.6737419366836548, testing loss: 1.872211217880249\n",
      "Accuracy: 0.3158\n",
      "epoch: 4, step: 700, training loss: 1.9230917692184448, testing loss: 1.7376519441604614\n",
      "Accuracy: 0.4516\n",
      "epoch: 4, step: 710, training loss: 1.7489687204360962, testing loss: 1.3990920782089233\n",
      "Accuracy: 0.5000\n",
      "epoch: 4, step: 720, training loss: 1.5798954963684082, testing loss: 1.960009217262268\n",
      "Accuracy: 0.3529\n",
      "epoch: 4, step: 730, training loss: 1.5447394847869873, testing loss: 1.2325440645217896\n",
      "Accuracy: 0.5357\n",
      "epoch: 4, step: 740, training loss: 1.6304491758346558, testing loss: 1.5973775386810303\n",
      "Accuracy: 0.4444\n",
      "epoch: 4, step: 750, training loss: 1.6260064840316772, testing loss: 1.7183209657669067\n",
      "Accuracy: 0.2791\n",
      "epoch: 4, step: 760, training loss: 1.3877086639404297, testing loss: 1.886022925376892\n",
      "Accuracy: 0.2903\n",
      "epoch: 4, step: 770, training loss: 1.5406403541564941, testing loss: 1.629428505897522\n",
      "Accuracy: 0.2083\n",
      "epoch: 4, step: 780, training loss: 1.7507001161575317, testing loss: 1.2447509765625\n",
      "Accuracy: 0.5926\n",
      "epoch: 4, step: 790, training loss: 1.537126064300537, testing loss: 1.6307779550552368\n",
      "Accuracy: 0.3750\n",
      "epoch: 4, step: 800, training loss: 1.773422360420227, testing loss: 1.895463228225708\n",
      "Accuracy: 0.4359\n",
      "epoch: 4, step: 810, training loss: 1.7724354267120361, testing loss: 1.568024754524231\n",
      "Accuracy: 0.3636\n",
      "epoch: 4, step: 820, training loss: 1.7499233484268188, testing loss: 1.8279536962509155\n",
      "Accuracy: 0.2857\n",
      "epoch: 4, step: 830, training loss: 1.8128715753555298, testing loss: 1.91313636302948\n",
      "Accuracy: 0.2727\n",
      "epoch: 4, step: 840, training loss: 1.5237789154052734, testing loss: 1.714425802230835\n",
      "Accuracy: 0.3448\n",
      "epoch: 4, step: 850, training loss: 1.3213026523590088, testing loss: 1.6719871759414673\n",
      "Accuracy: 0.3158\n",
      "epoch: 4, step: 860, training loss: 1.8463237285614014, testing loss: 1.7832889556884766\n",
      "Accuracy: 0.2333\n",
      "epoch: 4, step: 870, training loss: 1.6917680501937866, testing loss: 1.9476699829101562\n",
      "Accuracy: 0.3030\n",
      "epoch: 4, step: 880, training loss: 1.7311618328094482, testing loss: 1.8248178958892822\n",
      "Accuracy: 0.3704\n",
      "epoch: 4, step: 890, training loss: 1.4574390649795532, testing loss: 1.634469985961914\n",
      "Accuracy: 0.4062\n",
      "epoch: 4, step: 900, training loss: 1.6883716583251953, testing loss: 1.5280002355575562\n",
      "Accuracy: 0.3421\n",
      "epoch: 4, step: 910, training loss: 1.640109896659851, testing loss: 1.5722811222076416\n",
      "Accuracy: 0.4000\n",
      "epoch: 4, step: 920, training loss: 1.7013509273529053, testing loss: 1.4352526664733887\n",
      "Accuracy: 0.5312\n",
      "epoch: 4, step: 930, training loss: 1.493430495262146, testing loss: 1.8994324207305908\n",
      "Accuracy: 0.4194\n",
      "epoch: 4, step: 940, training loss: 1.7794855833053589, testing loss: 2.1860663890838623\n",
      "Accuracy: 0.3500\n",
      "epoch: 4, step: 950, training loss: 1.7568004131317139, testing loss: 2.143794059753418\n",
      "Accuracy: 0.3226\n",
      "epoch: 4, step: 960, training loss: 1.3251738548278809, testing loss: 1.6352107524871826\n",
      "Accuracy: 0.5676\n",
      "epoch: 4, step: 970, training loss: 1.5705839395523071, testing loss: 1.400671362876892\n",
      "Accuracy: 0.4054\n",
      "epoch: 4, step: 980, training loss: 1.937585711479187, testing loss: 1.754325032234192\n",
      "Accuracy: 0.4375\n",
      "epoch: 4, step: 990, training loss: 1.679875373840332, testing loss: 1.6402935981750488\n",
      "Accuracy: 0.5000\n",
      "epoch: 4, step: 1000, training loss: 1.6197974681854248, testing loss: 1.6670763492584229\n",
      "Accuracy: 0.3243\n",
      "epoch: 5, step: 10, training loss: 1.3918800354003906, testing loss: 1.533265233039856\n",
      "Accuracy: 0.2857\n",
      "epoch: 5, step: 20, training loss: 1.5547327995300293, testing loss: 2.019991397857666\n",
      "Accuracy: 0.3448\n",
      "epoch: 5, step: 30, training loss: 1.4036177396774292, testing loss: 1.759567379951477\n",
      "Accuracy: 0.1515\n",
      "epoch: 5, step: 40, training loss: 1.5384202003479004, testing loss: 1.6948057413101196\n",
      "Accuracy: 0.4000\n",
      "epoch: 5, step: 50, training loss: 1.7551876306533813, testing loss: 1.9213831424713135\n",
      "Accuracy: 0.2059\n",
      "epoch: 5, step: 60, training loss: 1.7276923656463623, testing loss: 1.7909668684005737\n",
      "Accuracy: 0.3611\n",
      "epoch: 5, step: 70, training loss: 1.6248618364334106, testing loss: 1.3943731784820557\n",
      "Accuracy: 0.4800\n",
      "epoch: 5, step: 80, training loss: 1.402747631072998, testing loss: 1.900816559791565\n",
      "Accuracy: 0.4688\n",
      "epoch: 5, step: 90, training loss: 1.5621086359024048, testing loss: 1.682523488998413\n",
      "Accuracy: 0.3125\n",
      "epoch: 5, step: 100, training loss: 1.6043150424957275, testing loss: 2.1882593631744385\n",
      "Accuracy: 0.2812\n",
      "epoch: 5, step: 110, training loss: 1.506359338760376, testing loss: 1.6697497367858887\n",
      "Accuracy: 0.4545\n",
      "epoch: 5, step: 120, training loss: 1.5897678136825562, testing loss: 1.9795150756835938\n",
      "Accuracy: 0.4000\n",
      "epoch: 5, step: 130, training loss: 1.4937187433242798, testing loss: 1.5559417009353638\n",
      "Accuracy: 0.5000\n",
      "epoch: 5, step: 140, training loss: 1.5318459272384644, testing loss: 2.0555505752563477\n",
      "Accuracy: 0.3333\n",
      "epoch: 5, step: 150, training loss: 1.854179859161377, testing loss: 1.6098048686981201\n",
      "Accuracy: 0.4595\n",
      "epoch: 5, step: 160, training loss: 1.8188151121139526, testing loss: 1.727407455444336\n",
      "Accuracy: 0.3030\n",
      "epoch: 5, step: 170, training loss: 1.754101037979126, testing loss: 1.7020899057388306\n",
      "Accuracy: 0.4194\n",
      "epoch: 5, step: 180, training loss: 1.746427059173584, testing loss: 1.782950758934021\n",
      "Accuracy: 0.4054\n",
      "epoch: 5, step: 190, training loss: 1.7223511934280396, testing loss: 1.8946232795715332\n",
      "Accuracy: 0.3333\n",
      "epoch: 5, step: 200, training loss: 1.8093022108078003, testing loss: 1.6203950643539429\n",
      "Accuracy: 0.3548\n",
      "epoch: 5, step: 210, training loss: 1.8145157098770142, testing loss: 1.5658385753631592\n",
      "Accuracy: 0.4516\n",
      "epoch: 5, step: 220, training loss: 1.4443176984786987, testing loss: 1.5578770637512207\n",
      "Accuracy: 0.4483\n",
      "epoch: 5, step: 230, training loss: 1.8614665269851685, testing loss: 2.2403922080993652\n",
      "Accuracy: 0.2727\n",
      "epoch: 5, step: 240, training loss: 1.8657984733581543, testing loss: 1.5934154987335205\n",
      "Accuracy: 0.5128\n",
      "epoch: 5, step: 250, training loss: 1.9768176078796387, testing loss: 1.8093719482421875\n",
      "Accuracy: 0.3939\n",
      "epoch: 5, step: 260, training loss: 1.62567937374115, testing loss: 1.7764559984207153\n",
      "Accuracy: 0.4400\n",
      "epoch: 5, step: 270, training loss: 1.6689753532409668, testing loss: 1.7680696249008179\n",
      "Accuracy: 0.3333\n",
      "epoch: 5, step: 280, training loss: 1.593333125114441, testing loss: 1.5081433057785034\n",
      "Accuracy: 0.3514\n",
      "epoch: 5, step: 290, training loss: 1.4133412837982178, testing loss: 1.5409440994262695\n",
      "Accuracy: 0.5926\n",
      "epoch: 5, step: 300, training loss: 1.7243094444274902, testing loss: 2.0844736099243164\n",
      "Accuracy: 0.2778\n",
      "epoch: 5, step: 310, training loss: 1.5738698244094849, testing loss: 2.285229206085205\n",
      "Accuracy: 0.3214\n",
      "epoch: 5, step: 320, training loss: 1.3891581296920776, testing loss: 1.592217206954956\n",
      "Accuracy: 0.4667\n",
      "epoch: 5, step: 330, training loss: 1.7234301567077637, testing loss: 1.857458472251892\n",
      "Accuracy: 0.4545\n",
      "epoch: 5, step: 340, training loss: 1.5165530443191528, testing loss: 1.9908418655395508\n",
      "Accuracy: 0.3143\n",
      "epoch: 5, step: 350, training loss: 1.5207722187042236, testing loss: 1.879062533378601\n",
      "Accuracy: 0.5600\n",
      "epoch: 5, step: 360, training loss: 1.5779305696487427, testing loss: 1.7304445505142212\n",
      "Accuracy: 0.3500\n",
      "epoch: 5, step: 370, training loss: 1.6058008670806885, testing loss: 1.286399006843567\n",
      "Accuracy: 0.4444\n",
      "epoch: 5, step: 380, training loss: 1.6579400300979614, testing loss: 2.06526255607605\n",
      "Accuracy: 0.2308\n",
      "epoch: 5, step: 390, training loss: 1.680984616279602, testing loss: 1.8797730207443237\n",
      "Accuracy: 0.4375\n",
      "epoch: 5, step: 400, training loss: 1.8565807342529297, testing loss: 1.7972302436828613\n",
      "Accuracy: 0.4571\n",
      "epoch: 5, step: 410, training loss: 1.5147032737731934, testing loss: 1.9242148399353027\n",
      "Accuracy: 0.3143\n",
      "epoch: 5, step: 420, training loss: 1.8511520624160767, testing loss: 1.9841041564941406\n",
      "Accuracy: 0.3103\n",
      "epoch: 5, step: 430, training loss: 1.7234786748886108, testing loss: 1.649219274520874\n",
      "Accuracy: 0.2121\n",
      "epoch: 5, step: 440, training loss: 1.667152762413025, testing loss: 1.2749371528625488\n",
      "Accuracy: 0.5517\n",
      "epoch: 5, step: 450, training loss: 1.5969218015670776, testing loss: 1.7659776210784912\n",
      "Accuracy: 0.2941\n",
      "epoch: 5, step: 460, training loss: 1.7309396266937256, testing loss: 2.5869638919830322\n",
      "Accuracy: 0.2500\n",
      "epoch: 5, step: 470, training loss: 1.8180005550384521, testing loss: 1.9626966714859009\n",
      "Accuracy: 0.5161\n",
      "epoch: 5, step: 480, training loss: 2.14408540725708, testing loss: 1.8363826274871826\n",
      "Accuracy: 0.4062\n",
      "epoch: 5, step: 490, training loss: 1.6528220176696777, testing loss: 2.0173981189727783\n",
      "Accuracy: 0.3889\n",
      "epoch: 5, step: 500, training loss: 1.5558234453201294, testing loss: 1.5345417261123657\n",
      "Accuracy: 0.3810\n",
      "epoch: 5, step: 510, training loss: 1.5814123153686523, testing loss: 1.5898112058639526\n",
      "Accuracy: 0.5294\n",
      "epoch: 5, step: 520, training loss: 1.7284222841262817, testing loss: 1.4805611371994019\n",
      "Accuracy: 0.4186\n",
      "epoch: 5, step: 530, training loss: 1.7112435102462769, testing loss: 1.8219455480575562\n",
      "Accuracy: 0.3750\n",
      "epoch: 5, step: 540, training loss: 1.518345832824707, testing loss: 1.7382766008377075\n",
      "Accuracy: 0.3235\n",
      "epoch: 5, step: 550, training loss: 1.5345077514648438, testing loss: 2.0171945095062256\n",
      "Accuracy: 0.3333\n",
      "epoch: 5, step: 560, training loss: 1.803236961364746, testing loss: 1.7012042999267578\n",
      "Accuracy: 0.4872\n",
      "epoch: 5, step: 570, training loss: 1.4515236616134644, testing loss: 1.7073633670806885\n",
      "Accuracy: 0.4884\n",
      "epoch: 5, step: 580, training loss: 1.6900662183761597, testing loss: 1.8943781852722168\n",
      "Accuracy: 0.3529\n",
      "epoch: 5, step: 590, training loss: 1.570946216583252, testing loss: 1.3336060047149658\n",
      "Accuracy: 0.4839\n",
      "epoch: 5, step: 600, training loss: 1.70819890499115, testing loss: 1.9367204904556274\n",
      "Accuracy: 0.3750\n",
      "epoch: 5, step: 610, training loss: 1.6421008110046387, testing loss: 2.0112974643707275\n",
      "Accuracy: 0.3750\n",
      "epoch: 5, step: 620, training loss: 2.0894384384155273, testing loss: 1.7740675210952759\n",
      "Accuracy: 0.3750\n",
      "epoch: 5, step: 630, training loss: 1.5544430017471313, testing loss: 2.085517644882202\n",
      "Accuracy: 0.2333\n",
      "epoch: 5, step: 640, training loss: 1.5591694116592407, testing loss: 1.5690656900405884\n",
      "Accuracy: 0.3438\n",
      "epoch: 5, step: 650, training loss: 1.6073130369186401, testing loss: 1.6273969411849976\n",
      "Accuracy: 0.4333\n",
      "epoch: 5, step: 660, training loss: 1.6837074756622314, testing loss: 1.6934150457382202\n",
      "Accuracy: 0.4412\n",
      "epoch: 5, step: 670, training loss: 1.6736631393432617, testing loss: 1.6288683414459229\n",
      "Accuracy: 0.3714\n",
      "epoch: 5, step: 680, training loss: 1.5217394828796387, testing loss: 1.5040600299835205\n",
      "Accuracy: 0.3448\n",
      "epoch: 5, step: 690, training loss: 1.5314661264419556, testing loss: 1.7717328071594238\n",
      "Accuracy: 0.4054\n",
      "epoch: 5, step: 700, training loss: 1.6292859315872192, testing loss: 1.6794116497039795\n",
      "Accuracy: 0.5556\n",
      "epoch: 5, step: 710, training loss: 1.7768553495407104, testing loss: 1.9833528995513916\n",
      "Accuracy: 0.3226\n",
      "epoch: 5, step: 720, training loss: 1.3809975385665894, testing loss: 1.81434965133667\n",
      "Accuracy: 0.2000\n",
      "epoch: 5, step: 730, training loss: 1.7462102174758911, testing loss: 1.7417415380477905\n",
      "Accuracy: 0.3182\n",
      "epoch: 5, step: 740, training loss: 1.4768955707550049, testing loss: 1.8706597089767456\n",
      "Accuracy: 0.2414\n",
      "epoch: 5, step: 750, training loss: 1.7318578958511353, testing loss: 1.9060462713241577\n",
      "Accuracy: 0.2941\n",
      "epoch: 5, step: 760, training loss: 1.422037959098816, testing loss: 1.8268322944641113\n",
      "Accuracy: 0.4571\n",
      "epoch: 5, step: 770, training loss: 1.5867314338684082, testing loss: 1.8090707063674927\n",
      "Accuracy: 0.3438\n",
      "epoch: 5, step: 780, training loss: 1.6090290546417236, testing loss: 1.5626157522201538\n",
      "Accuracy: 0.4865\n",
      "epoch: 5, step: 790, training loss: 1.5251365900039673, testing loss: 1.4716403484344482\n",
      "Accuracy: 0.3824\n",
      "epoch: 5, step: 800, training loss: 1.524099349975586, testing loss: 1.9942846298217773\n",
      "Accuracy: 0.3125\n",
      "epoch: 5, step: 810, training loss: 1.7905467748641968, testing loss: 1.7684552669525146\n",
      "Accuracy: 0.4412\n",
      "epoch: 5, step: 820, training loss: 1.5365995168685913, testing loss: 1.7326369285583496\n",
      "Accuracy: 0.3636\n",
      "epoch: 5, step: 830, training loss: 1.6496151685714722, testing loss: 1.8369944095611572\n",
      "Accuracy: 0.3929\n",
      "epoch: 5, step: 840, training loss: 1.4482311010360718, testing loss: 1.9198282957077026\n",
      "Accuracy: 0.2593\n",
      "epoch: 5, step: 850, training loss: 1.670553207397461, testing loss: 1.5382139682769775\n",
      "Accuracy: 0.4643\n",
      "epoch: 5, step: 860, training loss: 1.5823968648910522, testing loss: 1.885276198387146\n",
      "Accuracy: 0.3333\n",
      "epoch: 5, step: 870, training loss: 1.8525969982147217, testing loss: 1.882947325706482\n",
      "Accuracy: 0.3235\n",
      "epoch: 5, step: 880, training loss: 1.4115053415298462, testing loss: 1.538273572921753\n",
      "Accuracy: 0.4828\n",
      "epoch: 5, step: 890, training loss: 1.598308801651001, testing loss: 1.9643621444702148\n",
      "Accuracy: 0.4118\n",
      "epoch: 5, step: 900, training loss: 1.5882446765899658, testing loss: 1.7741553783416748\n",
      "Accuracy: 0.3438\n",
      "epoch: 5, step: 910, training loss: 1.755616545677185, testing loss: 1.7750779390335083\n",
      "Accuracy: 0.3548\n",
      "epoch: 5, step: 920, training loss: 1.8269892930984497, testing loss: 1.6858181953430176\n",
      "Accuracy: 0.5000\n",
      "epoch: 5, step: 930, training loss: 1.5019183158874512, testing loss: 1.2629691362380981\n",
      "Accuracy: 0.4857\n",
      "epoch: 5, step: 940, training loss: 1.6579779386520386, testing loss: 1.5682096481323242\n",
      "Accuracy: 0.4722\n",
      "epoch: 5, step: 950, training loss: 2.0374696254730225, testing loss: 1.5254266262054443\n",
      "Accuracy: 0.5143\n",
      "epoch: 5, step: 960, training loss: 1.7235318422317505, testing loss: 1.6480740308761597\n",
      "Accuracy: 0.2188\n",
      "epoch: 5, step: 970, training loss: 1.5530487298965454, testing loss: 1.743431568145752\n",
      "Accuracy: 0.3667\n",
      "epoch: 5, step: 980, training loss: 1.6876802444458008, testing loss: 1.753710150718689\n",
      "Accuracy: 0.3000\n",
      "epoch: 5, step: 990, training loss: 1.6932506561279297, testing loss: 2.0768332481384277\n",
      "Accuracy: 0.3514\n",
      "epoch: 5, step: 1000, training loss: 2.0266754627227783, testing loss: 1.494093894958496\n",
      "Accuracy: 0.4643\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(graph_gpt_model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "\n",
    "for epoch in range(5):\n",
    "    step = 1\n",
    "    for subgraph in loader:\n",
    "        step += 1\n",
    "        subgraph = subgraph.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = graph_gpt_model(subgraph)\n",
    "        loss = F.nll_loss(out[subgraph.train_mask], subgraph.y[subgraph.train_mask])\n",
    "\n",
    "        if (step + 1) % 10 == 0:\n",
    "            # print(f'step: {step+1}, training loss: {loss.item()}')\n",
    "            t_loss = F.nll_loss(out[subgraph.test_mask], subgraph.y[subgraph.test_mask])\n",
    "            print(f'epoch: {epoch + 1}, step: {step+1}, training loss: {loss.item()}, testing loss: {t_loss.item()}')\n",
    "\n",
    "        if (step + 1) % 10 == 0:\n",
    "            pred = graph_gpt_model(subgraph).argmax(dim=1)\n",
    "            correct = (pred[subgraph.test_mask] == subgraph.y[subgraph.test_mask]).sum()\n",
    "            acc = int(correct) / int(subgraph.test_mask.sum())\n",
    "            print(f'Accuracy: {acc:.4f}')\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
